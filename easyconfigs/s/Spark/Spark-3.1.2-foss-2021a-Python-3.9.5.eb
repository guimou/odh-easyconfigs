# Author: Guillaume Moutier (Red Hat)

easyblock = 'Tarball'

name = 'Spark'
version = '3.1.2'
versionsuffix = '-Python-%(pyver)s'

homepage = 'https://spark.apache.org'
description = """Apache Spark is a unified analytics engine for large-scale data processing.
 It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.
 It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning,
 GraphX for graph processing, and Structured Streaming for incremental computation and stream processing."""

toolchain = {'name': 'foss', 'version': '2021a'}

source_urls = [
    'https://dist.apache.org/repos/dist/release/%(namelower)s/%(namelower)s-%(version)s/',
    'https://archive.apache.org/dist/%(namelower)s/%(namelower)s-%(version)s/',
    'https://downloads.apache.org/%(namelower)s/%(namelower)s-%(version)s/'
]
sources = ['%(namelower)s-%(version)s-bin-hadoop3.2.tgz']
checksums = [
    '0d9cf9dbbb3b4215afebe7fa4748b012e406dd1f1ad2a61b993ac04adcb94eaa', # spark-3.1.2-bin-hadoop3.2.tgz
    ] 

dependencies = [
    ('Python', '3.9.5'),
    ('Java', '11', '', True),
    # ('Hadoop', '2.10.0', '-native'),
    ('Arrow', '5.0.0', versionsuffix),
]

exts_defaultclass = 'PythonPackage'
exts_default_options = {
    'source_urls': [PYPI_SOURCE],
    'download_dep_fail': True,
    'use_pip': True,
}

exts_list = [
    ('py4j', '0.10.9.2', {
        'checksums': ['624f97c363b8dd84822bc666b12fa7f7d97824632b2ff3d852cc491359ce7615'],
    }),
]

sanity_check_paths = {
    'files': ['bin/pyspark', 'bin/spark-shell'],
    'dirs': ['python']
}

sanity_check_commands = [
    "pyspark -h",
    "python -c 'import pyspark'",
]

modextrapaths = {'PYTHONPATH': ['python', 'lib/python%(pyshortver)s/site-packages']}

modextravars = {'SPARK_HOME': '%(installdir)s'}

moduleclass = 'devel'
